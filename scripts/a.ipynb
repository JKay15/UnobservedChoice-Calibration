{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "57d185e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Experiments. ID: 20251208_022937\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import itertools\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import replace\n",
    "\n",
    "# Ensure src is in python path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "\n",
    "from src.config import ExpConfig\n",
    "from src.engine.factory import EngineFactory\n",
    "from src.algorithms.solver import CalibrationSolver\n",
    "from src.modules.y_mappers import MonotoneYMapper\n",
    "from src.utils.metrics import compute_parameter_error, compute_rmse,compute_nll,compute_nll_from_gamma,compute_empirical_error_bound,compute_p0_from_logits\n",
    "# Imports for optimization and regret calculation\n",
    "from src.utils.optimization import solve_optimal_assortment, calculate_revenue\n",
    "\n",
    "# ==========================================\n",
    "# Global Setup\n",
    "# ==========================================\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "LOG_DIR = RESULTS_DIR / \"logs\"\n",
    "FIG_DIR = RESULTS_DIR / \"figures\"\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RUN_ID = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "def run_single_trial(cfg: ExpConfig, \n",
    "                     task_type: str = 'standard',      \n",
    "                     algo_type: str = 'mrc',           \n",
    "                     multi_sim_method: str = 'median', \n",
    "                     regret_need: bool = False,\n",
    "                     y_type: str = 'linear',\n",
    "                     z_type: str = 'stats',\n",
    "                     u_type: str = 'linear',\n",
    "                     context_type: str= 'concat',\n",
    "                     z_model_path: str = None) -> Dict[str, float]:\n",
    "    \n",
    "    # 1. Build Engine & Generate Data\n",
    "    engine = EngineFactory.build_synthetic_engine(\n",
    "        cfg, z_type=z_type, u_type=u_type, y_type=y_type, context_mapper_type=context_type,\n",
    "    )\n",
    "    data = engine.generate()\n",
    "    inputs = data['inputs']\n",
    "    truth = data['truth']\n",
    "    solver = CalibrationSolver(cfg)\n",
    "    # y_binary = torch.bernoulli(truth['p0']) # Not used currently\n",
    "    \n",
    "    # 初始化 regret 为 NaN (如果不需要计算，或者计算失败，保持为 NaN 方便后续处理)\n",
    "    avg_regret = float('nan')\n",
    "    duration = 0.0\n",
    "\n",
    "    # ==========================================\n",
    "    # Branch A: Multi-Simulator \n",
    "    # ==========================================\n",
    "    if task_type == 'multi_sim':\n",
    "        eta_true = truth['eta']\n",
    "        # ... (Simulator construction logic omitted for brevity, same as before) ...\n",
    "        # Sim 1-5 construction...\n",
    "        mapper1=MonotoneYMapper(cfg)\n",
    "        mapper2=MonotoneYMapper(replace(cfg, sim_bias_a=cfg.sim_bias_a+0.5, sim_bias_b=cfg.sim_bias_b*0.8))\n",
    "        mapper3=MonotoneYMapper(replace(cfg, sim_bias_a=cfg.sim_bias_a-0.5, sim_bias_b=cfg.sim_bias_b*1.2))\n",
    "        mapper4=MonotoneYMapper(replace(cfg, sim_bias_a=cfg.sim_bias_a+1.0, sim_bias_b=cfg.sim_bias_b*0.5))\n",
    "        mapper5=MonotoneYMapper(replace(cfg, sim_bias_a=cfg.sim_bias_a-10.0, sim_bias_b=cfg.sim_bias_b*15))\n",
    "        \n",
    "        y1 = mapper1(eta_true + torch.randn_like(eta_true) * 5) + torch.randn_like(eta_true) * 0.5\n",
    "        y2 = mapper2(eta_true + torch.randn_like(eta_true) * 5) + torch.randn_like(eta_true) * 0.5\n",
    "        y3 = mapper3(eta_true + torch.randn_like(eta_true) * 5) + torch.randn_like(eta_true) * 0.5\n",
    "        y4 = mapper4(eta_true + torch.randn_like(eta_true) * 5) + torch.randn_like(eta_true) * 0.5\n",
    "        \n",
    "        # 这里的 y5 建议按之前讨论修改为纯噪声以体现 Median 优势，或者保持原样\n",
    "        y5 = -10000.0 * mapper5(eta_true) + torch.randn_like(eta_true) * 5.0\n",
    "        \n",
    "        Y_multi = torch.stack([y1, y2, y3, y4, y5], dim=1)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        gamma_hat = solver.solve_multi_mrc(inputs['z'], inputs['s_hat'], Y_multi, method=multi_sim_method)\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            p0_pred = compute_p0_from_logits(inputs['z'], inputs['s_hat'], gamma_hat)\n",
    "\n",
    "    # ==========================================\n",
    "    # Branch B: Standard Calibration (+ Regret)\n",
    "    # ==========================================\n",
    "    else:\n",
    "        start_time = time.time()\n",
    "        if algo_type == 'linear':\n",
    "            gamma_hat = solver.solve_linear(inputs['z'], inputs['s_hat'], inputs['y'])\n",
    "        elif algo_type == 'mrc':\n",
    "            gamma_hat = solver.solve_mrc(inputs['z'], inputs['s_hat'], inputs['y'])\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown algo_type: {algo_type}\")\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            p0_pred = compute_p0_from_logits(inputs['z'], inputs['s_hat'], gamma_hat)\n",
    "            \n",
    "        # ==========================================\n",
    "        # 3. Downstream Assortment Regret (Test Phase)\n",
    "        # ==========================================\n",
    "        if regret_need:\n",
    "            # 只有 Linear Utility 才能精确定义 beta 误差\n",
    "            if u_type != 'linear':\n",
    "                avg_regret = float('nan') \n",
    "            else:\n",
    "                n_test_decisions = 50 \n",
    "                n_items_pool = 50     \n",
    "\n",
    "                # 1. 获取 True Beta\n",
    "                beta_true = engine.u_mapper.beta.detach() \n",
    "                \n",
    "                # 2. 获取 Estimated Beta (从 Engine 生成数据时导出的)\n",
    "                # [CRITICAL FIX] 这是一个必须保持一致的偏差\n",
    "                # 它模拟了 Stage 1 训练好的 Utility Model 参数\n",
    "                # 这个参数不仅生成了 s_hat (用于 Calibration), 也将被用于下面的决策\n",
    "                beta_hat = truth.get('beta_hat')\n",
    "                \n",
    "                # Fallback: 如果没有 noise 或者模式不对，beta_hat 默认为 beta_true\n",
    "                if beta_hat is None:\n",
    "                    beta_hat = beta_true\n",
    "                \n",
    "                # 确保设备一致\n",
    "                beta_hat = beta_hat.to(cfg.device)\n",
    "                \n",
    "                regret_list = []\n",
    "                \n",
    "                for _ in range(n_test_decisions):\n",
    "                    # A. 生成随机测试环境 (Context Z & Items)\n",
    "                    z_test = torch.randn(cfg.dim_z, device=cfg.device)\n",
    "                    items_x = torch.randn(n_items_pool, cfg.dim_item_feat, device=cfg.device)\n",
    "                    prices = torch.rand(n_items_pool, device=cfg.device) * 90 + 10\n",
    "                    \n",
    "                    # B. 计算 Utilities\n",
    "                    \n",
    "                    # Oracle (上帝视角): 使用 True Params\n",
    "                    u_items_true = items_x @ beta_true\n",
    "                    \n",
    "                    # Plug-in (决策视角): 使用 Hat Params\n",
    "                    # 注意：这里使用的是带偏差的 beta_hat\n",
    "                    u_items_hat = items_x @ beta_hat\n",
    "                    \n",
    "                    # C. Optimization (决策)\n",
    "                    \n",
    "                    # Oracle Set\n",
    "                    mask_opt, r_opt = solve_optimal_assortment(\n",
    "                        truth['gamma'], z_test, prices, u_items_true\n",
    "                    )\n",
    "                    \n",
    "                    # Estimated Set (Calibration 的 hat_gamma + Utility 的 hat_beta)\n",
    "                    # 这里的 \"误差抵消\" 会发生：gamma_hat 修正了由 beta_hat 引起的 scale shift\n",
    "                    mask_hat, _ = solve_optimal_assortment(\n",
    "                        gamma_hat, z_test, prices, u_items_hat\n",
    "                    )\n",
    "                    \n",
    "                    # D. Evaluation (评估)\n",
    "                    # 必须在 \"真实世界\" (True Params) 中评估两个集合的收入\n",
    "                    r_hat_realized = calculate_revenue(\n",
    "                        mask_hat, truth['gamma'], z_test, prices, u_items_true\n",
    "                    )\n",
    "                    \n",
    "                    # E. Regret Calculation\n",
    "                    if r_opt > 1e-6:\n",
    "                        regret = (r_opt - r_hat_realized) / r_opt\n",
    "                    else:\n",
    "                        regret = 0.0\n",
    "                    \n",
    "                    regret_list.append(regret)\n",
    "                \n",
    "                # 计算平均 Regret (%)\n",
    "                avg_regret = np.mean(regret_list) * 100.0 \n",
    "        \n",
    "    return {\n",
    "        'gamma_hat': gamma_hat,\n",
    "        'gamma_true': truth['gamma'],\n",
    "        'p0_pred': p0_pred,\n",
    "        'p0_true': truth['p0'],\n",
    "        'time': duration,\n",
    "        'regret': avg_regret\n",
    "    }\n",
    "\n",
    "# # ==========================================\n",
    "# # 1. Unified Atomic Trial Runner\n",
    "# # ==========================================\n",
    "# def run_single_trial(cfg: ExpConfig, \n",
    "#                      task_type: str = 'standard',      \n",
    "#                      algo_type: str = 'mrc',           \n",
    "#                      multi_sim_method: str = 'median', \n",
    "#                      regret_need: bool = False,\n",
    "#                      y_type: str = 'linear',\n",
    "#                      z_type: str = 'stats',\n",
    "#                      u_type: str = 'linear',\n",
    "#                      context_type: str= 'concat',\n",
    "#                      z_model_path: str = None) -> Dict[str, float]:\n",
    "    \n",
    "#     # 1. Build Engine & Generate Data\n",
    "#     engine = EngineFactory.build_synthetic_engine(\n",
    "#         cfg, z_type=z_type, u_type=u_type, y_type=y_type, context_mapper_type=context_type,\n",
    "#     )\n",
    "#     data = engine.generate()\n",
    "#     inputs = data['inputs']\n",
    "#     truth = data['truth']\n",
    "#     solver = CalibrationSolver(cfg)\n",
    "#     y_binary = torch.bernoulli(truth['p0'])\n",
    "    \n",
    "#     # ==========================================\n",
    "#     # Branch A: Multi-Simulator \n",
    "#     # ==========================================\n",
    "#     if task_type == 'multi_sim':\n",
    "#         eta_true = truth['eta']\n",
    "#         # Sim 1: (Good Signal)\n",
    "#         mapper1=MonotoneYMapper(cfg)\n",
    "#         mapper2=MonotoneYMapper(replace(cfg, sim_bias_a=cfg.sim_bias_a+0.5, sim_bias_b=cfg.sim_bias_b*0.8))\n",
    "#         mapper3=MonotoneYMapper(replace(cfg, sim_bias_a=cfg.sim_bias_a-0.5, sim_bias_b=cfg.sim_bias_b*1.2))\n",
    "#         mapper4=MonotoneYMapper(replace(cfg, sim_bias_a=cfg.sim_bias_a+1.0, sim_bias_b=cfg.sim_bias_b*0.5))\n",
    "#         mapper5=MonotoneYMapper(replace(cfg, sim_bias_a=cfg.sim_bias_a-10.0, sim_bias_b=cfg.sim_bias_b*15))\n",
    "#         y1 = mapper1(eta_true+ torch.randn_like(eta_true) * 5) + torch.randn_like(eta_true) * 0.5\n",
    "#         y2 = mapper2(eta_true+ torch.randn_like(eta_true) * 5) + torch.randn_like(eta_true) * 0.5\n",
    "#         y3 = mapper3(eta_true+ torch.randn_like(eta_true) * 5) + torch.randn_like(eta_true) * 0.5\n",
    "#         y4 = mapper4(eta_true+ torch.randn_like(eta_true) * 5) + torch.randn_like(eta_true) * 0.5\n",
    "        \n",
    "#         y5 = -10000.0 * mapper5(eta_true) + torch.randn_like(eta_true) * 5.0\n",
    "        \n",
    "#         Y_multi = torch.stack([y1, y2, y3, y4, y5], dim=1)\n",
    "        \n",
    "#         start_time = time.time()\n",
    "#         gamma_hat = solver.solve_multi_mrc(inputs['z'], inputs['s_hat'], Y_multi, method=multi_sim_method)\n",
    "#         duration = time.time() - start_time\n",
    "        \n",
    "#         # 使用修正后的 metrics 计算 NLL\n",
    "#         # nll_score = compute_nll_from_gamma(gamma_hat, inputs['z'], inputs['s_hat'], y_binary)\n",
    "#         p0_pred=compute_p0_from_logits(inputs['z'], inputs['s_hat'], gamma_hat)\n",
    "#     # ==========================================\n",
    "#     # Branch B: Standard Calibration (+ Regret)\n",
    "#     # ==========================================\n",
    "#     else:\n",
    "#         start_time = time.time()\n",
    "#         if algo_type == 'linear':\n",
    "#             gamma_hat = solver.solve_linear(inputs['z'], inputs['s_hat'], inputs['y'])\n",
    "#         elif algo_type == 'mrc':\n",
    "#             gamma_hat = solver.solve_mrc(inputs['z'], inputs['s_hat'], inputs['y'])\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unknown algo_type: {algo_type}\")\n",
    "#         duration = time.time() - start_time\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             p0_pred = compute_p0_from_logits(inputs['z'],inputs['s_hat'],gamma_hat)\n",
    "            \n",
    "#         avg_regret = 0.0\n",
    "#         # ==========================================\n",
    "#         # 3. Downstream Assortment Regret (Test Phase)\n",
    "#         # ==========================================\n",
    "#         if regret_need:\n",
    "#             if u_type != 'linear':\n",
    "#                 avg_regret = float('nan') \n",
    "#             else:\n",
    "#                 n_test_decisions = 50\n",
    "#                 n_items_pool = 50     \n",
    "\n",
    "#                 beta_true = engine.u_mapper.beta.detach() \n",
    "                \n",
    "#                 est_sigma = cfg.est_noise_sigma\n",
    "#                 d_item = cfg.dim_item_feat\n",
    "                \n",
    "#                 if est_sigma > 0:\n",
    "#                     if getattr(cfg, 'noise_distribution', 'gaussian') == 'uniform':\n",
    "#                         # Strict bound logic: max norm <= sigma\n",
    "#                         bound = est_sigma / np.sqrt(d_item)\n",
    "#                         delta_beta = (torch.rand(d_item, device=cfg.device) * 2 - 1) * bound\n",
    "#                     else:\n",
    "#                         # Gaussian logic: expected norm approx sigma\n",
    "#                         raw = torch.randn(d_item, device=cfg.device)\n",
    "#                         delta_beta = raw / (raw.norm() + 1e-9) * est_sigma\n",
    "#                 else:\n",
    "#                     delta_beta = torch.zeros_like(beta_true)\n",
    "                \n",
    "#                 beta_hat = beta_true + delta_beta\n",
    "                \n",
    "#                 regret_list = []\n",
    "                \n",
    "#                 for _ in range(n_test_decisions):\n",
    "#                     z_test = torch.randn(cfg.dim_z, device=cfg.device)\n",
    "                    \n",
    "#                     # Random Item Pool (Features X and Prices r)\n",
    "#                     # Items X: (n_pool, d_item)\n",
    "#                     items_x = torch.randn(n_items_pool, d_item, device=cfg.device)\n",
    "#                     # Prices r: Uniform [10, 100]\n",
    "#                     prices = torch.rand(n_items_pool, device=cfg.device) * 90 + 10\n",
    "                    \n",
    "#                     # True Utilities\n",
    "#                     u_items_true = items_x @ beta_true\n",
    "                    \n",
    "#                     # Estimated Utilities\n",
    "#                     u_items_hat = items_x @ beta_hat\n",
    "                    \n",
    "#                     # C.(Optimization)\n",
    "#                     mask_opt, r_opt = solve_optimal_assortment(\n",
    "#                         truth['gamma'], z_test, prices, u_items_true\n",
    "#                     )\n",
    "                    \n",
    "#                     mask_hat, _ = solve_optimal_assortment(\n",
    "#                         gamma_hat, z_test, prices, u_items_hat\n",
    "#                     )\n",
    "                    \n",
    "#                     # D.(Evaluation)\n",
    "#                     r_hat_realized = calculate_revenue(\n",
    "#                         mask_hat, truth['gamma'], z_test, prices, u_items_true\n",
    "#                     )\n",
    "                    \n",
    "#                     # E. Regret\n",
    "#                     # Relative Regret: (Opt - Realized) / Opt\n",
    "#                     if r_opt > 1e-6:\n",
    "#                         regret = (r_opt - r_hat_realized) / r_opt\n",
    "#                     else:\n",
    "#                         regret = 0.0\n",
    "                    \n",
    "#                     regret_list.append(regret)\n",
    "                \n",
    "#                 avg_regret = np.mean(regret_list) * 100.0 \n",
    "        \n",
    "        \n",
    "#     return {\n",
    "#         'gamma_hat': gamma_hat,\n",
    "#         'gamma_true': truth['gamma'],\n",
    "#         'p0_pred': p0_pred,\n",
    "#         'p0_true': truth['p0'],\n",
    "#         'time': duration,\n",
    "#         'regret': avg_regret\n",
    "#     }\n",
    "\n",
    "# ==========================================\n",
    "# 2. Universal Experiment Runner (Corrected)\n",
    "# ==========================================\n",
    "def run_experiment_grid(\n",
    "    base_cfg: ExpConfig,\n",
    "    x_axis_name: str,\n",
    "    x_values: List[Any],\n",
    "    compare_axis_name: Any = None, \n",
    "    compare_values: List[Any] = None,\n",
    "    cross_product: bool = True,\n",
    "    n_seeds: int = 5,\n",
    "    regret_need:bool= False,\n",
    "    # Defaults\n",
    "    default_task_type: str = 'standard',       \n",
    "    default_algo_type: str = 'mrc',\n",
    "    default_multi_sim_method: str = 'median',  \n",
    "    default_y_type: str = 'monotone',\n",
    "    default_z_type: str = 'neural',\n",
    "    default_u_type: str = 'linear',\n",
    "    default_context_type: str= 'concat',\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    # --- 1. 解析参数组合 (Cartesian Product Logic) ---\n",
    "    if compare_axis_name is None:\n",
    "        comp_keys = []\n",
    "        comp_iter = [()] # 空元组占位，只循环 x_axis\n",
    "    elif isinstance(compare_axis_name, str):\n",
    "        # 兼容旧接口：单变量对比\n",
    "        comp_keys = [compare_axis_name]\n",
    "        # 包装成 tuple 列表: [('mrc',), ('linear',)]\n",
    "        comp_iter = [(v,) for v in compare_values] \n",
    "    else:\n",
    "        # 多变量情况\n",
    "        comp_keys = compare_axis_name\n",
    "        if cross_product:\n",
    "            # [Old Behavior] Cartesian Product\n",
    "            # values=[[A,B], [C,D]] -> (A,C), (A,D), (B,C), (B,D)\n",
    "            comp_iter = list(itertools.product(*compare_values))\n",
    "        else:\n",
    "            # [New Behavior] Direct Zip / Coupled List\n",
    "            # values=[(A,C), (B,D)] -> (A,C), (B,D)\n",
    "            # 用户直接传入 list of tuples\n",
    "            comp_iter = compare_values\n",
    "\n",
    "    print(f\"\\n=== Running Grid: X={x_axis_name} | Cross Validating: {comp_keys} ===\")\n",
    "    \n",
    "    records = []\n",
    "    total_iters = len(x_values) * len(comp_iter) * n_seeds\n",
    "    pbar = tqdm(total=total_iters, desc=\"Progress\")\n",
    "    \n",
    "    for x_val in x_values:\n",
    "        for comp_vals in comp_iter:\n",
    "            # 构造当前对比参数字典 e.g. {'algo_type': 'mrc', 'y_type': 'linear'}\n",
    "            current_comp_params = dict(zip(comp_keys, comp_vals))\n",
    "            \n",
    "            # 生成绘图用的 Hue Label e.g. \"mrc-linear\"\n",
    "            if not comp_keys:\n",
    "                combo_label = \"Default\"\n",
    "            else:\n",
    "                combo_label = \"-\".join([str(v) for v in comp_vals])\n",
    "\n",
    "            for seed in range(n_seeds):\n",
    "                # 1. Config Setup\n",
    "                # 优先使用 override 的 x_val\n",
    "                current_cfg_args = {\n",
    "                    'seed': seed + 1000,\n",
    "                    x_axis_name: x_val \n",
    "                }\n",
    "                \n",
    "                # 2. Dynamic Parameter Resolution\n",
    "                # 优先级: Override Params > Defaults\n",
    "                params = {\n",
    "                    'task_type': default_task_type,\n",
    "                    'algo_type': default_algo_type,\n",
    "                    'multi_sim_method': default_multi_sim_method,\n",
    "                    'y_type': default_y_type,\n",
    "                    'z_type': default_z_type,\n",
    "                    'u_type': default_u_type,\n",
    "                    'context_type': default_context_type,\n",
    "                    'regret_need':regret_need,\n",
    "                }\n",
    "                \n",
    "                # 应用 X 轴参数 (如果 X 轴控制的是 params 里的东西)\n",
    "                if x_axis_name in params:\n",
    "                    params[x_axis_name] = x_val\n",
    "                \n",
    "                # 应用 对比轴 参数\n",
    "                for k, v in current_comp_params.items():\n",
    "                    if k in params:\n",
    "                        params[k] = v\n",
    "                \n",
    "                # 3. Create Config\n",
    "                # 将 params 中属于 Config 属性的部分同步进去\n",
    "                cfg_args = current_cfg_args.copy()\n",
    "                for k, v in params.items():\n",
    "                    if hasattr(base_cfg, k):\n",
    "                        cfg_args[k] = v\n",
    "                \n",
    "                # 如果 x_axis 是 Config 的属性 (如 n_samples)，也要同步\n",
    "                if hasattr(base_cfg, x_axis_name):\n",
    "                    cfg_args[x_axis_name] = x_val\n",
    "\n",
    "                cfg = ExpConfig(**{**base_cfg.__dict__, **cfg_args})\n",
    "                set_seed(cfg.seed)\n",
    "                \n",
    "                # 4. Run Trial\n",
    "                metrics = run_single_trial(\n",
    "                    cfg, \n",
    "                    task_type=params['task_type'],\n",
    "                    algo_type=params['algo_type'],\n",
    "                    multi_sim_method=params['multi_sim_method'],\n",
    "                    regret_need=params['regret_need'],\n",
    "                    y_type=params['y_type'],\n",
    "                    z_type=params['z_type'],\n",
    "                    u_type=params['u_type'],\n",
    "                    context_type=params['context_type'],\n",
    "                )\n",
    "                \n",
    "                # 5. Record\n",
    "                record = {\n",
    "                    x_axis_name: x_val,\n",
    "                    'seed': seed,\n",
    "                    'combo_label': combo_label, # 关键：用于 hue\n",
    "                    **current_comp_params,      # 记录具体参数方便查阅\n",
    "                    **metrics                   # 包含 Tensor 数据\n",
    "                }\n",
    "                record['n_samples'] = cfg.n_samples # 确保 n_samples 总是存在\n",
    "                \n",
    "                records.append(record)\n",
    "                pbar.update(1)\n",
    "                \n",
    "    pbar.close()\n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    save_name = f\"grid_{x_axis_name}\"\n",
    "    if comp_keys:\n",
    "        comp_str = \"_\".join(comp_keys)\n",
    "        save_name += f\"_vs_{comp_str}\"\n",
    "    \n",
    "    # df.to_csv(LOG_DIR / f\"{save_name}_{RUN_ID}.csv\", index=False)\n",
    "    pkl_path = LOG_DIR / f\"{save_name}_{RUN_ID}.pkl\"\n",
    "    df.to_pickle(pkl_path)\n",
    "    print(f\"Saved full data (with Tensors) to: {pkl_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ==========================================\n",
    "# 3. Universal Plotter (Updated)\n",
    "# ==========================================\n",
    "def plot_metric_scaling(\n",
    "    df: pd.DataFrame,\n",
    "    x_col: str,\n",
    "    x_label: str,\n",
    "    y_label: str,\n",
    "    hue_col: Optional[str] = None,\n",
    "    title: str = \"Scaling Analysis\",\n",
    "):\n",
    "    print(f\"\\n>>> Plotting {y_label} vs {x_label}...\")\n",
    "    \n",
    "    # --- Step 1: Device Wash (MPS -> CPU) ---\n",
    "    # 确保所有 Tensor 都在 CPU 上，方便后续 numpy/torch 操作\n",
    "    tensor_cols = ['p0_pred', 'p0_true', 'gamma_hat', 'gamma_true']\n",
    "    \n",
    "    def move_to_cpu(val):\n",
    "        if isinstance(val, torch.Tensor):\n",
    "            return val.detach().cpu()\n",
    "        return val\n",
    "\n",
    "    plot_df = df.copy()\n",
    "    for col in tensor_cols:\n",
    "        if col in plot_df.columns:\n",
    "            # 简单检查第一行\n",
    "            first_val = plot_df[col].iloc[0]\n",
    "            if isinstance(first_val, torch.Tensor) and first_val.device.type != 'cpu':\n",
    "                plot_df[col] = plot_df[col].apply(move_to_cpu)\n",
    "                \n",
    "    # --- Step 2: 核心聚合逻辑 (区分 P0 和 Gamma) ---\n",
    "    # sub_df 包含同一个 (x, hue) 下的 n_seeds 次实验数据\n",
    "    def compute_pooled_metric(sub_df):\n",
    "        \n",
    "        # =========================================\n",
    "        # Case A: P0 相关 (需要拼接样本，做全量分布统计)\n",
    "        # =========================================\n",
    "        if 'p0' in y_label or 'nll' in y_label or 'rmse' in y_label:\n",
    "            # 1. 拼接 (Pooling)\n",
    "            # sub_df['p0_pred'] 是一个包含 n_seeds 个 Tensor 的 Series\n",
    "            # 每个 Tensor 长度为 n_samples\n",
    "            # cat 后变成一个巨大的 1D Tensor，长度为 n_seeds * n_samples\n",
    "            all_preds = torch.cat(list(sub_df['p0_pred'])).float().numpy()\n",
    "            all_trues = torch.cat(list(sub_df['p0_true'])).float().numpy()\n",
    "            \n",
    "            # 2. 计算指标\n",
    "            if 'nll' in y_label:\n",
    "                epsilon = 1e-7\n",
    "                all_preds = np.clip(all_preds, epsilon, 1 - epsilon)\n",
    "                # 计算所有样本的 NLL 平均值\n",
    "                nll = - (all_trues * np.log(all_preds) + (1 - all_trues) * np.log(1 - all_preds))\n",
    "                return np.mean(nll)\n",
    "            \n",
    "            elif 'p0' in y_label and 'error' in y_label:\n",
    "                # 解析 delta (e.g., \"p0_error_0.2\" -> delta=0.2 -> 80% 分位点)\n",
    "                # 默认 0.05 (95% 分位点)\n",
    "                try:\n",
    "                    parts = y_label.split('_')\n",
    "                    if len(parts) > 2 and parts[-1].replace('.', '', 1).isdigit():\n",
    "                        delta = float(parts[-1])\n",
    "                    else:\n",
    "                        delta = 0.3\n",
    "                except:\n",
    "                    delta = 0.3\n",
    "                \n",
    "                # 计算绝对误差分布\n",
    "                abs_diff = np.abs(all_preds - all_trues)\n",
    "                # 返回大样本的分位点\n",
    "                return np.quantile(abs_diff, 1.0 - delta)\n",
    "            \n",
    "            elif 'rmse' in y_label:\n",
    "                return np.sqrt(np.mean((all_preds - all_trues)**2))\n",
    "\n",
    "        # =========================================\n",
    "        # Case B: Gamma 相关 (需要行内计算，再行间平均)\n",
    "        # =========================================\n",
    "        elif 'gamma' in y_label:\n",
    "            # 1. 堆叠 (Stacking)\n",
    "            # 变成 (n_seeds, dim_z) 的矩阵\n",
    "            hat_matrix = torch.stack(list(sub_df['gamma_hat']))\n",
    "            true_matrix = torch.stack(list(sub_df['gamma_true']))\n",
    "            \n",
    "            # 2. 计算每一行的 L2 Error\n",
    "            # dim=1 表示沿着特征维度求范数 -> 得到 (n_seeds, ) 的误差向量\n",
    "            l2_errors = torch.norm(hat_matrix - true_matrix, p=2, dim=1)\n",
    "            \n",
    "            # 3. 返回这些误差的平均值\n",
    "            return l2_errors.mean().item()\n",
    "\n",
    "        # =========================================\n",
    "        # Case C: Regret (本身就是标量，直接平均)\n",
    "        # =========================================\n",
    "        elif 'regret' in y_label:\n",
    "            # 安全检查：如果该列不存在或全为空（比如没开启计算），返回 NaN 而不是 0\n",
    "            # 返回 0 会误导以为效果完美，返回 NaN 图上该点会断开\n",
    "            if 'regret' not in sub_df.columns:\n",
    "                return float('nan')\n",
    "            \n",
    "            # 过滤掉可能的 None/NaN (有些 seed 可能失败)\n",
    "            valid_regrets = sub_df['regret'].dropna()\n",
    "            \n",
    "            if valid_regrets.empty:\n",
    "                return float('nan')\n",
    "                \n",
    "            return valid_regrets.mean()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown y_label type for metric computation: {y_label}\")\n",
    "            \n",
    "        return 0.0\n",
    "    # --- Step 3: GroupBy & Apply ---\n",
    "    df = plot_df.groupby([x_col, hue_col]).apply(compute_pooled_metric, include_groups=False).reset_index(name=y_label)\n",
    "    \n",
    "    # 1. Empirical Data Plot\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'serif',\n",
    "        'font.size': 18,\n",
    "        'axes.labelsize': 18,\n",
    "        'axes.titlesize': 18,\n",
    "        'xtick.labelsize': 18,\n",
    "        'ytick.labelsize': 18,\n",
    "        'legend.fontsize': 16,\n",
    "        'lines.linewidth': 2.5\n",
    "    })\n",
    "    \n",
    "    palette = None\n",
    "    markers = True\n",
    "    dashes = True\n",
    "        \n",
    "    \n",
    "    if hue_col:\n",
    "        unique_methods = sorted(df[hue_col].unique())\n",
    "        \n",
    "        # 1. Define Style Mapping\n",
    "        # Colors: Red (MRC), Blue (Linear), Green (Sim), Orange (Oracle)\n",
    "        # Lines: Solid, Dash-dot, Dashed, Dotted\n",
    "        style_spec = {\n",
    "            'mrc':    {'color': '#d62728', 'dashes': \"\"},           # Red Solid\n",
    "            'median':   {'color': '#d62728', 'dashes': \"\"},\n",
    "            'monotone': {'color': '#d62728', 'dashes': \"\"},\n",
    "            'linear': {'color': '#1f77b4', 'dashes': (3, 1, 1, 1)}, # Blue Dash-dot\n",
    "            'logit_mean': {'color': '#1f77b4', 'dashes': (3, 1, 1, 1)},\n",
    "            'sim':    {'color': '#2ca02c', 'dashes': (2, 2)},       # Green Dashed\n",
    "            'oracle': {'color': '#ff7f0e', 'dashes': (1, 1)},       # Orange Dotted\n",
    "            'bound':  {'color': '#ff7f0e', 'dashes': (1, 1)}\n",
    "        }\n",
    "        \n",
    "        fallback_colors = ['#9467bd', '#8c564b', '#e377c2', '#7f7f7f']\n",
    "        \n",
    "        color_map = {}\n",
    "        dash_map = {}\n",
    "        \n",
    "        for idx, m in enumerate(unique_methods):\n",
    "            m_lower = str(m).lower()\n",
    "            matched = False\n",
    "            \n",
    "            for key, spec in style_spec.items():\n",
    "                if key in m_lower:\n",
    "                    color_map[m] = spec['color']\n",
    "                    dash_map[m] = spec['dashes']\n",
    "                    matched = True\n",
    "                    break\n",
    "            \n",
    "            if not matched:\n",
    "                color_map[m] = fallback_colors[idx % len(fallback_colors)]\n",
    "                dash_map[m] = \"\" # Default Solid\n",
    "\n",
    "        # 2. Draw Plot\n",
    "        sns.lineplot(\n",
    "            data=df,\n",
    "            x=x_col,\n",
    "            y=y_label,\n",
    "            hue=hue_col,\n",
    "            style=hue_col,\n",
    "            palette=color_map,\n",
    "            dashes=dash_map,\n",
    "            markers=False,      \n",
    "            linewidth=2.5\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        sns.lineplot(\n",
    "            data=df, x=x_label, y=y_label, \n",
    "            marker=None, linewidth=2.5, color='#ff7f0e'\n",
    "        )\n",
    "\n",
    "    # 3. Title Formatting\n",
    "    x_label_text = x_label\n",
    "        \n",
    "    if 'nll' in y_label.lower():\n",
    "        ylabel = \"NLL of P0\"\n",
    "    elif 'p0' in y_label.lower():\n",
    "        ylabel = r\"Empirical P0 error bound($\\delta=$\" + y_label.split('_')[-1] + r\")\"\n",
    "    elif 'gamma' in y_label.lower():\n",
    "        ylabel = r\"$\\gamma$ L2 Estimation Error\"\n",
    "    elif 'regret' in y_label.lower():\n",
    "        ylabel = \"Relative Revenue Regret (%)\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown y_label type: {y_label}\")\n",
    "\n",
    "    if x_label == 'n_samples':\n",
    "        final_title = title\n",
    "    else:\n",
    "        n_val = df.iloc[0].get('n_samples', 'Unknown')\n",
    "        final_title = f\"{title}\"\n",
    "        \n",
    "    plt.title(final_title, pad=12)\n",
    "    plt.xlabel(x_label_text)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True, which='both', alpha=0.3)\n",
    "    plt.legend(frameon=True, edgecolor='#cccccc', framealpha=0.9)\n",
    "    \n",
    "    clean_title = title.lower().replace(\" \", \"_\").replace(\":\", \"\")\n",
    "    RUN_id=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "    save_path = FIG_DIR / f\"{clean_title}_{RUN_id}.png\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plot saved to {save_path}\")\n",
    "    plt.close()\n",
    "# ==========================================\n",
    "# 4. Main Execution\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Starting Experiments. ID: {RUN_ID}\")\n",
    "    print(f\"Device: {torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')}\")\n",
    "\n",
    "    base_cfg = ExpConfig(\n",
    "        n_samples=2000,\n",
    "        dim_z=200,\n",
    "        est_noise_sigma=1,\n",
    "        utility_mode='additive',\n",
    "        noise_distribution='gaussian',\n",
    "        sim_bias_a=1.0,\n",
    "        sim_bias_b=1\n",
    "    )\n",
    "    mrc_cfg = ExpConfig(\n",
    "        n_samples=2000,\n",
    "        dim_z=200,\n",
    "        est_noise_sigma=1,\n",
    "        utility_mode='additive',\n",
    "        noise_distribution='uniform',\n",
    "        sim_bias_a=1.0,\n",
    "        sim_bias_b=1\n",
    "    )\n",
    "    linear_cfg = ExpConfig(\n",
    "        n_samples=2000,\n",
    "        dim_z=200,\n",
    "        est_noise_sigma=1,\n",
    "        utility_mode=\"structural\",\n",
    "        noise_distribution=\"gaussian\",\n",
    "        sim_bias_a=1.0,\n",
    "        sim_bias_b=1\n",
    "    )\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Exp 1: Convergence vs Sample Size (n)\n",
    "    # ------------------------------------------------------\n",
    "    def exp1():\n",
    "        df_n = run_experiment_grid(\n",
    "            base_cfg=base_cfg,\n",
    "            x_axis_name='n_samples',\n",
    "            x_values=[100,150 ,200, 500,1000,1500 ,2000,4000], \n",
    "            compare_axis_name='algo_type',\n",
    "            compare_values=['linear', 'mrc'],\n",
    "            default_y_type='monotone',\n",
    "            default_z_type='neural',\n",
    "            default_context_type='concat'\n",
    "        )\n",
    "        plot_metric_scaling(\n",
    "            df_n,x_col='n_samples', x_label='N', y_label='nll', hue_col='algo_type',\n",
    "            title=\"Exp 1: Convergence vs Sample Size\",\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Exp 2: Robustness to Utility Noise (tau)\n",
    "    # ------------------------------------------------------\n",
    "    # change the form of tau noise from sigma to high probability bound\n",
    "    def exp2():\n",
    "        df_tau = run_experiment_grid(\n",
    "            base_cfg=base_cfg,\n",
    "            x_axis_name='est_noise_sigma', \n",
    "            x_values=[0.0, 0.5, 1.0, 1.5, 2.0,2.5,3.0],\n",
    "            compare_axis_name='algo_type',\n",
    "            compare_values=['linear', 'mrc'],\n",
    "            default_y_type='monotone',\n",
    "            default_z_type='neural',\n",
    "            default_context_type='concat'\n",
    "        )\n",
    "        plot_metric_scaling(\n",
    "            df_tau, x_col='est_noise_sigma',x_label=r'$\\bar{\\tau}$', y_label='nll', hue_col='algo_type',\n",
    "            title=\"Exp 2: Robustness to Utility Noise (tau)\"\n",
    "        )\n",
    "    # ------------------------------------------------------\n",
    "    # Exp 3: Bias Type Impact (Linear vs Monotone)\n",
    "    # ------------------------------------------------------\n",
    "    def exp3():\n",
    "        df_bias = run_experiment_grid(\n",
    "            base_cfg=linear_cfg,\n",
    "            x_axis_name='n_samples', \n",
    "            x_values=[ 100, 200, 500, 1000,1500, 2000,2500], \n",
    "            compare_axis_name='y_type', \n",
    "            compare_values=['linear', 'monotone'],\n",
    "            default_algo_type='mrc',\n",
    "            n_seeds=10,\n",
    "            default_z_type='neural',\n",
    "            default_context_type='concat'\n",
    "        )\n",
    "        plot_metric_scaling(\n",
    "            df_bias,x_col='n_samples', x_label='N', y_label='nll', hue_col='y_type',\n",
    "            title=\"Exp 3: MRC Robustness across Simulator Types\"\n",
    "        )\n",
    "    # ------------------------------------------------------\n",
    "    # Exp 4: Bias Type Impact (Linear vs Monotone)\n",
    "    # ------------------------------------------------------\n",
    "    def exp4():\n",
    "        df_bias = run_experiment_grid(\n",
    "            base_cfg=mrc_cfg,\n",
    "            x_axis_name='n_samples', \n",
    "            x_values=[100, 200, 500,7500,1500, 2500,6000], \n",
    "            compare_axis_name='y_type', \n",
    "            compare_values=['linear', 'monotone'],\n",
    "            default_algo_type='mrc',\n",
    "            n_seeds=5,\n",
    "            default_z_type='neural',\n",
    "            default_context_type='concat'\n",
    "        )\n",
    "        plot_metric_scaling(\n",
    "            df_bias,x_col='n_samples', x_label='N', y_label='p0_error_0.3', hue_col='y_type',\n",
    "            title=\"Exp 4: MRC Robustness across Simulator Types\"\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Exp 5: Assortment Optimization Regret\n",
    "    # ------------------------------------------------------\n",
    "    # Note: This uses the SAME data frame as Exp 2 or Exp 4 conceptually, \n",
    "    # but we re-run it to be clean (or we could reuse df_d if we want to save time).\n",
    "    # Here we run explicitly to ensure 'regret' metric is focused.\n",
    "    # Exp 5: Assortment Regret\n",
    "    def exp5():\n",
    "        df_regret = run_experiment_grid(\n",
    "            base_cfg=base_cfg, # Use the harder config\n",
    "            x_axis_name='n_samples',\n",
    "            x_values=[50, 100, 200, 500, 1000, 2000,4000], \n",
    "            compare_axis_name='algo_type',\n",
    "            compare_values=['linear', 'mrc'],\n",
    "            default_y_type='monotone',\n",
    "            default_z_type='neural',\n",
    "            default_context_type='concat'\n",
    "        )\n",
    "        plot_metric_scaling(\n",
    "            df_regret,x_col='n_samples', x_label='N', y_label='regret', hue_col='algo_type',\n",
    "            title=\"Exp 5: Assortment Regret Analysis\",\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Exp 6: Multi-Simulator Robustness (Mean vs Median)\n",
    "    # ------------------------------------------------------\n",
    "    def exp6():\n",
    "        df_multi = run_experiment_grid(\n",
    "            base_cfg=base_cfg,\n",
    "            x_axis_name='n_samples',\n",
    "            x_values=[50, 100, 200, 500, 1000, 2000,4000], \n",
    "            compare_axis_name='multi_sim_method', \n",
    "            compare_values=['logit_mean', 'median','weighted_mean'], \n",
    "            default_task_type='multi_sim',\n",
    "            default_z_type='neural',\n",
    "            default_context_type='concat'\n",
    "        )\n",
    "        plot_metric_scaling(\n",
    "            df_multi,x_col='n_samples', x_label='N', y_label='p0_error_0.3', hue_col='multi_sim_method',\n",
    "            title=\"Exp 6: Multi-Simulator Robustness\"\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Exp 7: Simulator Noise Impact (Testing Flip Probability)\n",
    "    # ------------------------------------------------------\n",
    "    def exp7():\n",
    "        df_noise = run_experiment_grid(\n",
    "            base_cfg=base_cfg,\n",
    "            x_axis_name='sim_noise_sigma',\n",
    "            x_values=[0.1, 0.5, 1.0, 2.0, 3.0, 5.0],\n",
    "            compare_axis_name='algo_type',\n",
    "            compare_values=['linear', 'mrc'],\n",
    "            default_y_type='monotone',\n",
    "            default_z_type='neural',\n",
    "            default_context_type='concat'\n",
    "        )\n",
    "        \n",
    "        plot_metric_scaling(\n",
    "            df_noise,x_col='sim_noise_sigma', x_label=r'$\\sigma$', y_label='p0_error_0.3', hue_col='algo_type',\n",
    "            title=\"Exp 7: Robustness to Simulator Noise\"\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Exp 8: Assortment Size Impact (Market Density)\n",
    "    # ------------------------------------------------------\n",
    "    def exp8():\n",
    "        df_size = run_experiment_grid(\n",
    "            base_cfg=base_cfg,\n",
    "            x_axis_name='max_assortment_size',\n",
    "            x_values=[5, 10, 20, 50, 100], \n",
    "            compare_axis_name='algo_type',\n",
    "            compare_values=['linear', 'mrc'],\n",
    "            default_y_type='monotone',\n",
    "            default_z_type='neural',\n",
    "            default_context_type='concat'\n",
    "        )\n",
    "        \n",
    "        plot_metric_scaling(\n",
    "            df_size,x_col='max_assortment_size', x_label=r'$\\mathcal{S}_{\\max}$', y_label='p0_error_0.3', hue_col='algo_type',\n",
    "            title=\"Exp 8: Impact of Assortment Size\"\n",
    "        )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21edfd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Grid: X=n_samples | Cross Validating: ['algo_type'] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 80/80 [01:07<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full data (with Tensors) to: results/logs/grid_n_samples_vs_algo_type_20251206_205535.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_exp1 = run_experiment_grid(\n",
    "            base_cfg=base_cfg,\n",
    "            x_axis_name='n_samples',\n",
    "            x_values=[100,150 ,200, 500,1000,1500 ,2000,4000], \n",
    "            compare_axis_name='algo_type',\n",
    "            compare_values=['linear', 'mrc'],\n",
    "            default_y_type='monotone',\n",
    "            default_z_type='neural',\n",
    "            n_seeds=5,\n",
    "            default_context_type='concat'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9abc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp1 = df_exp1[df_exp1['n_samples'] != 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8084f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Plotting p0_error_0.3 vs N...\n",
      "Plot saved to results/figures/exp_1_convergence_vs_sample_size_20251206_205535.png\n"
     ]
    }
   ],
   "source": [
    "plot_metric_scaling(\n",
    "    df_exp1,x_col='n_samples', x_label='N', y_label='p0_error_0.3', hue_col='algo_type',\n",
    "    title=\"Exp 1: Convergence vs Sample Size\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2420c58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Grid: X=est_noise_sigma | Cross Validating: ['algo_type'] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 70/70 [01:46<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full data (with Tensors) to: results/logs/grid_est_noise_sigma_vs_algo_type_20251207_195941.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_exp2 = run_experiment_grid(\n",
    "            base_cfg=base_cfg,\n",
    "            x_axis_name='est_noise_sigma', \n",
    "            x_values=[0.0, 0.5, 1.0, 1.5, 2.0,2.5,3.0],\n",
    "            compare_axis_name='algo_type',\n",
    "            compare_values=['linear', 'mrc'],\n",
    "            default_y_type='monotone',\n",
    "            default_z_type='neural',\n",
    "            default_context_type='concat'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40502c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Plotting p0_error_0.3 vs $\\bar{\\tau}$...\n",
      "Plot saved to results/figures/exp_2_robustness_to_utility_noise_(tau)_20251207_195941.png\n"
     ]
    }
   ],
   "source": [
    "plot_metric_scaling(\n",
    "    df_exp2, x_col='est_noise_sigma',x_label=r'$\\bar{\\tau}$', y_label='p0_error_0.3', hue_col='algo_type',\n",
    "    title=\"Exp 2: Robustness to Utility Noise (tau)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edddd637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Grid: X=n_samples | Cross Validating: ['y_type'] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 160/160 [00:57<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full data (with Tensors) to: results/logs/grid_n_samples_vs_y_type_20251207_195941.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_exp3 = run_experiment_grid(\n",
    "            base_cfg=linear_cfg,\n",
    "            x_axis_name='n_samples', \n",
    "            x_values=[ 100, 200, 500, 1000,1500, 2000,2500,4000], \n",
    "            compare_axis_name='y_type', \n",
    "            compare_values=['linear', 'monotone'],\n",
    "            default_algo_type='linear',\n",
    "            n_seeds=10,\n",
    "            default_z_type='neural',\n",
    "            default_context_type='concat'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef32071b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Plotting nll vs N...\n",
      "Plot saved to results/figures/exp_3_linear_robustness_across_simulator_types_20251207_203834_256113.png\n"
     ]
    }
   ],
   "source": [
    "plot_metric_scaling(\n",
    "    df_exp3,x_col='n_samples', x_label='N', y_label='nll', hue_col='y_type',\n",
    "    title=\"Exp 3: linear Robustness across Simulator Types\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4f59225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Grid: X=n_samples | Cross Validating: ['y_type'] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 70/70 [01:20<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full data (with Tensors) to: results/logs/grid_n_samples_vs_y_type_20251207_201251.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_exp3_mrc = run_experiment_grid(\n",
    "            base_cfg=linear_cfg,\n",
    "            x_axis_name='n_samples', \n",
    "            x_values=[ 100, 200, 1000,1500, 2000,3000,6000], \n",
    "            compare_axis_name='y_type', \n",
    "            compare_values=['linear', 'monotone'],\n",
    "            default_algo_type='mrc',\n",
    "            n_seeds=5,\n",
    "            default_z_type='neural',\n",
    "            default_context_type='concat'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddeda202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Plotting nll vs N...\n",
      "Plot saved to results/figures/exp_3_mrc_robustness_across_simulator_types_20251207_205138_273738.png\n"
     ]
    }
   ],
   "source": [
    "plot_metric_scaling(\n",
    "    df_exp3_mrc,x_col='n_samples', x_label='N', y_label='nll', hue_col='y_type',\n",
    "    title=\"Exp 3: MRC Robustness across Simulator Types\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d417803a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Grid: X=n_samples | Cross Validating: ['y_type'] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 80/80 [01:37<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full data (with Tensors) to: results/logs/grid_n_samples_vs_y_type_20251207_201251.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_exp4 = run_experiment_grid(\n",
    "            base_cfg=mrc_cfg,\n",
    "            x_axis_name='n_samples', \n",
    "            x_values=[100, 200, 500,1500,2000, 2500,4000,7500], \n",
    "            compare_axis_name='y_type', \n",
    "            compare_values=['linear', 'monotone'],\n",
    "            default_algo_type='mrc',\n",
    "            n_seeds=5,\n",
    "            default_z_type='neural',\n",
    "            default_context_type='concat'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4374104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Plotting nll vs N...\n",
      "Plot saved to results/figures/exp_4_mrc_robustness_across_simulator_types_20251207_211043_493436.png\n"
     ]
    }
   ],
   "source": [
    "plot_metric_scaling(\n",
    "            df_exp4,x_col='n_samples', x_label='N', y_label='nll', hue_col='y_type',\n",
    "            title=\"Exp 4: MRC Robustness across Simulator Types\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73eb625f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Grid: X=n_samples | Cross Validating: ['multi_sim_method'] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 420/420 [04:09<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full data (with Tensors) to: results/logs/grid_n_samples_vs_multi_sim_method_20251207_201251.pkl\n"
     ]
    }
   ],
   "source": [
    "df_exp6 = run_experiment_grid(\n",
    "            base_cfg=base_cfg,\n",
    "            x_axis_name='n_samples',\n",
    "            x_values=[50, 100, 200, 500, 1000, 2000,4000], \n",
    "            compare_axis_name='multi_sim_method', \n",
    "            compare_values=['logit_mean', 'median','weighted_mean'], \n",
    "            default_task_type='multi_sim',\n",
    "            default_z_type='neural',\n",
    "            n_seeds=20,\n",
    "            default_context_type='concat'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a40f02c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Plotting nll vs N...\n",
      "Plot saved to results/figures/exp_6_multi-simulator_robustness_20251207_211548_949301.png\n"
     ]
    }
   ],
   "source": [
    "plot_metric_scaling(\n",
    "    df_exp6,x_col='n_samples', x_label='N', y_label='nll', hue_col='multi_sim_method',\n",
    "    title=\"Exp 6: Multi-Simulator Robustness\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de221aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Grid: X=n_samples | Cross Validating: ['multi_sim_method'] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   3%|▎         | 70/2100 [00:02<01:11, 28.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] MRC theta_s is too small (0.0). Fallback to naive reg.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   6%|▋         | 134/2100 [00:04<00:32, 60.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n",
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   8%|▊         | 158/2100 [00:04<00:28, 69.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n",
      "[Warning] Median yielded no valid pairs. Returning random init.\n",
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   8%|▊         | 174/2100 [00:05<00:27, 70.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n",
      "[Warning] Median yielded no valid pairs. Returning random init.\n",
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   9%|▉         | 190/2100 [00:05<00:27, 70.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  10%|▉         | 206/2100 [00:05<00:26, 71.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  18%|█▊        | 370/2100 [00:11<01:59, 14.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] MRC theta_s is too small (0.0). Fallback to naive reg.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  21%|██        | 431/2100 [00:14<00:43, 38.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  22%|██▏       | 456/2100 [00:15<00:39, 41.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n",
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  23%|██▎       | 476/2100 [00:15<00:38, 42.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  23%|██▎       | 486/2100 [00:15<00:38, 41.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  24%|██▍       | 506/2100 [00:16<00:38, 41.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  32%|███▏      | 669/2100 [00:29<03:27,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] MRC theta_s is too small (0.0). Fallback to naive reg.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  36%|███▌      | 751/2100 [00:36<00:58, 23.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  36%|███▌      | 757/2100 [00:36<00:57, 23.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  37%|███▋      | 772/2100 [00:37<01:00, 22.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  37%|███▋      | 781/2100 [00:37<01:00, 21.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  47%|████▋     | 992/2100 [01:10<06:01,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] MRC theta_s is too small (4.622863343684003e-05). Fallback to naive reg.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  50%|█████     | 1055/2100 [01:38<06:01,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  61%|██████    | 1278/2100 [05:44<33:04,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] MRC theta_s is too small (7.13606732460903e-06). Fallback to naive reg.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  65%|██████▍   | 1355/2100 [06:57<05:40,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  66%|██████▌   | 1380/2100 [07:11<06:38,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  79%|███████▉  | 1655/2100 [13:17<06:37,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  80%|████████  | 1680/2100 [13:44<06:19,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  93%|█████████▎| 1955/2100 [22:22<03:16,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 2100/2100 [26:00<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full data (with Tensors) to: results/logs/grid_n_samples_vs_multi_sim_method_20251206_221153.pkl\n"
     ]
    }
   ],
   "source": [
    "df_exp61 = run_experiment_grid(\n",
    "            base_cfg=base_cfg,\n",
    "            x_axis_name='n_samples',\n",
    "            x_values=[50, 100, 200, 500, 1000, 2000,4000], \n",
    "            compare_axis_name='multi_sim_method', \n",
    "            compare_values=['logit_mean', 'median','weighted_mean'], \n",
    "            default_task_type='multi_sim',\n",
    "            default_z_type='neural',\n",
    "            n_seeds=40,\n",
    "            default_context_type='concat'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc97d242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Plotting nll vs N...\n",
      "Plot saved to results/figures/exp_6_multi-simulator_robustness_20251207_212300_571187.png\n"
     ]
    }
   ],
   "source": [
    "plot_metric_scaling(\n",
    "    df_exp61,x_col='n_samples', x_label='N', y_label='nll', hue_col='multi_sim_method',\n",
    "    title=\"Exp 6: Multi-Simulator Robustness\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b6a2efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Grid: X=n_samples | Cross Validating: ['multi_sim_method'] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   3%|▎         | 69/2100 [00:02<01:10, 28.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] MRC theta_s is too small (0.0). Fallback to naive reg.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   6%|▋         | 136/2100 [00:04<00:31, 61.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n",
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   7%|▋         | 151/2100 [00:04<00:29, 65.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n",
      "[Warning] Median yielded no valid pairs. Returning random init.\n",
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   8%|▊         | 173/2100 [00:05<00:30, 64.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n",
      "[Warning] Median yielded no valid pairs. Returning random init.\n",
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   9%|▉         | 187/2100 [00:05<00:29, 64.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  10%|█         | 211/2100 [00:05<00:27, 69.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  18%|█▊        | 370/2100 [00:11<01:53, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] MRC theta_s is too small (0.0). Fallback to naive reg.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  20%|██        | 429/2100 [00:14<00:45, 36.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  22%|██▏       | 457/2100 [00:14<00:40, 40.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n",
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  22%|██▏       | 472/2100 [00:15<00:40, 40.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  23%|██▎       | 487/2100 [00:15<00:40, 39.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  24%|██▍       | 507/2100 [00:16<00:38, 41.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  32%|███▏      | 669/2100 [00:28<02:53,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] MRC theta_s is too small (0.0). Fallback to naive reg.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  36%|███▌      | 750/2100 [00:35<01:12, 18.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  36%|███▌      | 758/2100 [00:35<01:08, 19.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  37%|███▋      | 770/2100 [00:36<01:07, 19.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  37%|███▋      | 781/2100 [00:36<01:04, 20.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  47%|████▋     | 992/2100 [01:14<07:15,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] MRC theta_s is too small (4.622863343684003e-05). Fallback to naive reg.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  50%|█████     | 1055/2100 [01:48<08:29,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  61%|██████    | 1278/2100 [06:52<37:03,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] MRC theta_s is too small (7.13606732460903e-06). Fallback to naive reg.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  65%|██████▍   | 1355/2100 [08:51<11:38,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  66%|██████▌   | 1380/2100 [09:14<08:05,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  79%|███████▉  | 1655/2100 [16:30<07:13,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  80%|████████  | 1680/2100 [16:53<06:51,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  93%|█████████▎| 1955/2100 [23:56<02:37,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Median yielded no valid pairs. Returning random init.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 2100/2100 [26:46<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full data (with Tensors) to: results/logs/grid_n_samples_vs_multi_sim_method_20251207_201251.pkl\n"
     ]
    }
   ],
   "source": [
    "df_exp62 = run_experiment_grid(\n",
    "            base_cfg=base_cfg,\n",
    "            x_axis_name='n_samples',\n",
    "            x_values=[50, 100, 200, 500, 1000, 2000,4000], \n",
    "            compare_axis_name='multi_sim_method', \n",
    "            compare_values=['logit_mean', 'median','weighted_mean'], \n",
    "            default_task_type='multi_sim',\n",
    "            default_z_type='neural',\n",
    "            n_seeds=100,\n",
    "            default_context_type='concat'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5180e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Plotting nll vs N...\n",
      "Plot saved to results/figures/exp_6_multi-simulator_robustness_20251207_215751_365793.png\n"
     ]
    }
   ],
   "source": [
    "plot_metric_scaling(\n",
    "    df_exp61,x_col='n_samples', x_label='N', y_label='nll', hue_col='multi_sim_method',\n",
    "    title=\"Exp 6: Multi-Simulator Robustness\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ec35083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_cfg = ExpConfig(\n",
    "        n_samples=2000,\n",
    "        dim_z=200,\n",
    "        est_noise_sigma=0.1,\n",
    "        sim_noise_sigma=0.1,\n",
    "        utility_mode='additive',\n",
    "        noise_distribution='uniform',\n",
    "        sim_bias_a=1.0,\n",
    "        sim_bias_b=1,\n",
    "        min_assortment_size = 50,\n",
    "        max_assortment_size = 100 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6686ab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Grid: X=n_samples | Cross Validating: ['algo_type', 'y_type'] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Progress: 100%|██████████| 60/60 [01:34<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full data (with Tensors) to: results/logs/grid_n_samples_vs_algo_type_y_type_20251208_022937.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_exp5 = run_experiment_grid(\n",
    "    base_cfg=regret_cfg, # Use the harder config\n",
    "    x_axis_name='n_samples',\n",
    "    x_values=[100, 200, 500, 1000,4000,5000], \n",
    "    compare_axis_name=['algo_type', 'y_type'],\n",
    "    compare_values=[\n",
    "        ('linear', 'linear'),  \n",
    "        ('mrc', 'monotone')    \n",
    "    ],\n",
    "    n_seeds=5,\n",
    "    cross_product=False,\n",
    "    regret_need=True,\n",
    "    default_y_type='monotone',\n",
    "    default_z_type='neural',\n",
    "    default_context_type='concat',   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b6b231bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Plotting regret vs N...\n",
      "Plot saved to results/figures/exp_5_assortment_regret_analysis_20251208_023718_825820.png\n"
     ]
    }
   ],
   "source": [
    "plot_metric_scaling(\n",
    "    df_exp5,x_col='n_samples', x_label='N', y_label='regret', hue_col='algo_type',\n",
    "    title=\"Exp 5: Assortment Regret Analysis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decb694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"/Users/xiongjiangkai/xjk_coding/UnobservedChoice_Calibration/results/logs/grid_sim_bias_b_vs_algo_type_y_type_20251216_152826.pkl\"\n",
    "\n",
    "df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2adb07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sim_bias_b', 'seed', 'combo_label', 'algo_type', 'y_type', 'gamma_hat',\n",
       "       'gamma_true', 'p0_pred', 'p0_true', 'time', 'regret', 'n_samples'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a2f09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53e4160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['linear-linear', 'linear-monotone', 'mrc-linear', 'mrc-monotone'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.combo_label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd14ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = df[\"sim_bias_b\"].min(), df['sim_bias_b'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8be79d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 5.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_min, x_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54cc8d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import itertools\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import replace\n",
    "from matplotlib.ticker import ScalarFormatter, NullFormatter\n",
    "\n",
    "# Ensure src is in python path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "\n",
    "from src.config import ExpConfig\n",
    "from src.engine.factory import EngineFactory\n",
    "from src.algorithms.solver import CalibrationSolver\n",
    "from src.modules.y_mappers import MonotoneYMapper\n",
    "from src.utils.metrics import compute_p0_from_logits\n",
    "\n",
    "# Imports for optimization and regret calculation\n",
    "from src.utils.optimization import solve_optimal_assortment, calculate_revenue\n",
    "\n",
    "# ==========================================\n",
    "# Global Setup\n",
    "# ==========================================\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "LOG_DIR = RESULTS_DIR / \"logs\"\n",
    "FIG_DIR = RESULTS_DIR / \"figures\"\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RUN_ID = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# ==========================================\n",
    "# [AESTHETICS] Global Style Configuration\n",
    "# ==========================================\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# 1. 颜色映射 (Color Map) - 语义绑定\n",
    "COLOR_MAP = {\n",
    "    \"mrc\": \"tab:red\",  # 红色\n",
    "    \"linear\": \"tab:blue\",  # 蓝色\n",
    "    \"median\": \"tab:green\",  # 绿色\n",
    "    \"weighted\": \"tab:orange\",  # 橙色\n",
    "    \"mean\": \"tab:purple\",  # 紫色\n",
    "    \"naive\": \"tab:gray\",  # 灰色\n",
    "    \"sim\": \"tab:gray\",  # 灰色\n",
    "    \"default\": \"black\",\n",
    "}\n",
    "\n",
    "# 2. 纹理库 (Texture Bank) - 字典序分配\n",
    "# 逻辑: (LineStyle, Marker)\n",
    "# [User Request]: Index 3 (4th) is 'x', Index 4 (5th) is 'D'\n",
    "TEXTURE_BANK = [\n",
    "    (\"-\", \"o\"),  # 1. 实线 + 圆圈 (最强)\n",
    "    (\"--\", \"s\"),  # 2. 虚线 + 方块\n",
    "    (\"-.\", \"^\"),  # 3. 点划线 + 三角\n",
    "    (\":\", \"x\"),  # 4. 点线 + 叉号 (Swapped)\n",
    "    (\"-\", \"D\"),  # 5. 实线 + 菱形 (Swapped)\n",
    "    (\"--\", \"*\"),  # 6. 虚线 + 星号\n",
    "    (\"-.\", \"v\"),  # 7. 点划线 + 倒三角\n",
    "    (\":\", \"P\"),  # 8. 点线 + 加号\n",
    "]\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def plot_metric_scaling(\n",
    "    df: pd.DataFrame,\n",
    "    x_col: str,\n",
    "    x_label: str,\n",
    "    y_label: str,\n",
    "    hue_col: Optional[str] = None,\n",
    "    title: str = \"Scaling Analysis\",\n",
    "    y_top_margin: Optional[float] = None,\n",
    "    legend_loc: str = \"upper right\",\n",
    "    log_y: Optional[bool] = None,\n",
    "    log_x: Optional[bool] = None,\n",
    "):\n",
    "    print(f\"\\n>>> [Plot] {y_label} vs {x_label}...\")\n",
    "\n",
    "    # --- 1. Data Prep (Unchanged) ---\n",
    "    tensor_cols = [\"p0_pred\", \"p0_true\", \"gamma_hat\", \"gamma_true\"]\n",
    "\n",
    "    def move_to_cpu(val):\n",
    "        if isinstance(val, torch.Tensor):\n",
    "            return val.detach().cpu()\n",
    "        return val\n",
    "\n",
    "    plot_df = df.copy()\n",
    "    for col in tensor_cols:\n",
    "        if col in plot_df.columns:\n",
    "            if len(plot_df) > 0 and isinstance(plot_df[col].iloc[0], torch.Tensor):\n",
    "                plot_df[col] = plot_df[col].apply(move_to_cpu)\n",
    "\n",
    "    # --- 2. Metric Computation (Unchanged) ---\n",
    "    def compute_pooled_metric(sub_df):\n",
    "        if len(sub_df) == 0:\n",
    "            return float(\"nan\")\n",
    "\n",
    "        if \"p0\" in y_label or \"nll\" in y_label:\n",
    "            all_preds = torch.cat(list(sub_df[\"p0_pred\"])).float().numpy()\n",
    "            all_trues = torch.cat(list(sub_df[\"p0_true\"])).float().numpy()\n",
    "\n",
    "            if \"nll\" in y_label:\n",
    "                epsilon = 1e-7\n",
    "                all_preds = np.clip(all_preds, epsilon, 1 - epsilon)\n",
    "                nll = -(\n",
    "                    all_trues * np.log(all_preds)\n",
    "                    + (1 - all_trues) * np.log(1 - all_preds)\n",
    "                )\n",
    "                return np.mean(nll)\n",
    "            elif \"error\" in y_label:\n",
    "                abs_diff = np.abs(all_preds - all_trues)\n",
    "                return np.quantile(abs_diff, 0.70)\n",
    "\n",
    "        elif \"gamma\" in y_label:\n",
    "            hat_matrix = torch.stack(list(sub_df[\"gamma_hat\"]))\n",
    "            true_matrix = torch.stack(list(sub_df[\"gamma_true\"]))\n",
    "            l2_errors = torch.norm(hat_matrix - true_matrix, p=2, dim=1)\n",
    "            return l2_errors.mean().item()\n",
    "\n",
    "        elif \"regret\" in y_label:\n",
    "            valid_regrets = sub_df[\"regret\"].dropna()\n",
    "            return valid_regrets.mean() if not valid_regrets.empty else float(\"nan\")\n",
    "        return 0.0\n",
    "\n",
    "    if plot_df.empty:\n",
    "        print(\"[Warning] No data to plot.\")\n",
    "        return\n",
    "\n",
    "    df_agg = (\n",
    "        plot_df.groupby([x_col, hue_col] if hue_col else [x_col])\n",
    "        .apply(compute_pooled_metric, include_groups=False)\n",
    "        .reset_index(name=y_label)\n",
    "    )\n",
    "\n",
    "    # --- 3. Style Setup ---\n",
    "    sns.set_theme(style=\"ticks\", context=\"paper\")\n",
    "    plt.rcParams.update(\n",
    "        {\n",
    "            \"font.family\": \"serif\",\n",
    "            \"font.serif\": [\"Times New Roman\"],\n",
    "            \"font.size\": 20,\n",
    "            \"axes.labelsize\": 22,\n",
    "            \"axes.titlesize\": 22,\n",
    "            \"xtick.labelsize\": 18,\n",
    "            \"ytick.labelsize\": 18,\n",
    "            \"legend.fontsize\": 16,\n",
    "            \"lines.linewidth\": 2.5,\n",
    "            \"lines.markersize\": 9,\n",
    "            \"axes.grid\": True,\n",
    "            \"grid.linestyle\": \"--\",\n",
    "            \"grid.alpha\": 0.4,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    LABEL_MAP = {\n",
    "        \"n_samples\": \"n\",\n",
    "        \"est_noise_sigma\": x_label,\n",
    "        \"sim_noise_sigma\": r\"$\\sigma_{\\epsilon}$\",\n",
    "        \"dim_z\": \"d\",\n",
    "        \"max_assortment_size\": r\"$|\\mathcal{S}|_{\\max}$\",\n",
    "        \"gamma_error\": \"Parameter Estimation Error\",\n",
    "        \"p0_error\": \"Empirical p0 Error\",\n",
    "        \"nll\": \"Negative Log-Likelihood\",\n",
    "        \"regret\": \"Sub-optimality (%)\",\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # --- 4. Plotting Loop (UPDATED LOGIC) ---\n",
    "    # Sort hues alphabetically to ensure deterministic order\n",
    "    unique_hues = sorted(df_agg[hue_col].unique()) if hue_col else [None]\n",
    "\n",
    "    for idx, hue_val in enumerate(unique_hues):\n",
    "        if hue_val:\n",
    "            subset = df_agg[df_agg[hue_col] == hue_val].sort_values(x_col)\n",
    "            label_str = str(hue_val)\n",
    "        else:\n",
    "            subset = df_agg.sort_values(x_col)\n",
    "            label_str = \"Default\"\n",
    "\n",
    "        # [NEW LOGIC START] =========================================\n",
    "\n",
    "        # A. Texture by Dictionary Order (Strict Indexing)\n",
    "        # 无论是什么 Label，只要排第几，就用第几号纹理\n",
    "        tex_idx = idx % len(TEXTURE_BANK)\n",
    "        ls, marker = TEXTURE_BANK[tex_idx]\n",
    "\n",
    "        # B. Color by Semantic Name\n",
    "        s_lower = label_str.lower()\n",
    "        color = COLOR_MAP[\"default\"]\n",
    "        # Find matching color key\n",
    "        for k, v in COLOR_MAP.items():\n",
    "            if k in s_lower:\n",
    "                color = v\n",
    "                break\n",
    "\n",
    "        # C. Label Cleanup\n",
    "        # e.g. \"linear-monotone\" -> \"Linear (Monotone Sim)\"\n",
    "        clean_label = label_str.replace(\"_\", \" \").title()\n",
    "        clean_label = clean_label.replace(\"Mrc\", \"MRC\").replace(\"Linear\", \"Lin\")\n",
    "        if \"-\" in clean_label:\n",
    "            parts = clean_label.split(\"-\")\n",
    "            clean_label = f\"{parts[0]} ({parts[1]} Sim)\"\n",
    "\n",
    "        # Oracle cleanup\n",
    "        if \"Oracle\" in clean_label:\n",
    "            # 保持纹理分配不变，只在图例文字上做点微调（可选）\n",
    "            pass\n",
    "\n",
    "        # [NEW LOGIC END] ===========================================\n",
    "\n",
    "        ax.plot(\n",
    "            subset[x_col],\n",
    "            subset[y_label],\n",
    "            label=clean_label,\n",
    "            color=color,\n",
    "            linestyle=ls,\n",
    "            marker=marker,\n",
    "            alpha=0.9,\n",
    "        )\n",
    "\n",
    "    # --- 5. Axes & Ticks Logic (Preserved) ---\n",
    "    # X-Axis Log Logic\n",
    "    use_log_x = False\n",
    "    if log_x is not None:\n",
    "        use_log_x = log_x\n",
    "        x_min, x_max = df_agg[x_col].min(), df_agg[x_col].max()\n",
    "        if x_col == \"n_samples\" or \"sigma\" in x_col:\n",
    "            if x_min > 1e-9 and (x_max / x_min > 10):\n",
    "                use_log_x = True\n",
    "    if use_log_x:\n",
    "        ax.set_xscale(\"log\")\n",
    "        custom_ticks = {x_min, x_max}\n",
    "        if x_col == \"n_samples\" and x_min < 1000 < x_max:\n",
    "            custom_ticks.add(1000)\n",
    "\n",
    "        if (\"sigma\" in x_col or 'sim_bias_b' in x_col) and x_min < 1.0 < x_max:\n",
    "            custom_ticks.add(1.0)\n",
    "\n",
    "        ax.set_xticks(sorted(list(custom_ticks)))\n",
    "        ax.xaxis.set_major_formatter(ScalarFormatter())\n",
    "        ax.xaxis.set_minor_formatter(NullFormatter())\n",
    "\n",
    "    # Y-Axis Log Logic\n",
    "    use_log_y = False\n",
    "    if log_y is not None:\n",
    "        use_log_y = log_y\n",
    "    else:\n",
    "        y_min, y_max = df_agg[y_label].min(), df_agg[y_label].max()\n",
    "        if \"error\" in y_label or \"nll\" in y_label or \"regret\" in y_label:\n",
    "            if y_min > 1e-9 and (y_max / y_min > 20):\n",
    "                use_log_y = True\n",
    "\n",
    "    if use_log_y:\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.yaxis.set_major_formatter(ScalarFormatter())\n",
    "        ax.yaxis.set_minor_formatter(NullFormatter())\n",
    "        ax.yaxis.get_major_formatter().set_scientific(False)\n",
    "        ax.yaxis.get_major_formatter().set_useOffset(False)\n",
    "\n",
    "    # Grid\n",
    "    ax.grid(True, which=\"major\", linestyle=\"--\", linewidth=1.0, alpha=0.5)\n",
    "    ax.grid(True, which=\"minor\", linestyle=\":\", linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # --- 6. Layout & Legend ---\n",
    "    ax.set_xlabel(LABEL_MAP.get(x_col, x_label), fontweight=\"bold\")\n",
    "    ax.set_ylabel(LABEL_MAP.get(y_label, y_label), fontweight=\"bold\")\n",
    "    # ax.set_title(title, pad=15, fontweight='bold')\n",
    "\n",
    "    if y_top_margin:\n",
    "        curr_bottom, curr_top = ax.get_ylim()\n",
    "        if ax.get_yscale() == \"log\":\n",
    "            ax.set_ylim(curr_bottom, curr_top * (10**y_top_margin))\n",
    "        else:\n",
    "            ax.set_ylim(curr_bottom, curr_top * y_top_margin)\n",
    "\n",
    "    ax.legend(\n",
    "        loc=legend_loc, frameon=True, edgecolor=\"black\", framealpha=0.95, fancybox=False\n",
    "    )\n",
    "\n",
    "    clean_title = (\n",
    "        title.lower()\n",
    "        .replace(\" \", \"_\")\n",
    "        .replace(\":\", \"\")\n",
    "        .replace(\"$\", \"\")\n",
    "        .replace(\"\\\\\", \"\")\n",
    "    )\n",
    "    RUN_id = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_path = FIG_DIR / f\"{clean_title}_{RUN_id}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\", dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"   Saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ccd6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"/Users/xiongjiangkai/xjk_coding/UnobservedChoice_Calibration/results/logs/grid_sim_bias_b_vs_algo_type_y_type_20251216_195141.pkl\"\n",
    "\n",
    "df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6ca9c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [Plot] p0_error vs $b^*$...\n",
      "   Saved to results/figures/robustness_to_bias_magnitude_20251216_200142.png\n"
     ]
    }
   ],
   "source": [
    "plot_metric_scaling(\n",
    "            df,\n",
    "            x_col=\"sim_bias_b\",\n",
    "            x_label=r\"$b^*$\",\n",
    "            y_label=\"p0_error\",\n",
    "            hue_col=\"combo_label\",\n",
    "            title=\"Robustness to Bias Magnitude\",\n",
    "            y_top_margin=1.4,\n",
    "            log_y=False,\n",
    "            log_x=True, # Log scale X-axis makes it easier to see 0.1 vs 5.0\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".Data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
